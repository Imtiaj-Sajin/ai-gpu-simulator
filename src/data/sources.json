{
  "gpus": [
    {
      "id": "rtx-4070-ti-super",
      "name": "RTX 4070 Ti Super",
      "tier": "consumer",
      "vramGB": 16,
      "memoryBandwidthGBs": 672,
      "fp16Tflops": 82.6,
      "notes": "Ada Lovelace consumer GPU. FP16 TFLOPS is dense, not sparse.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-ti-super/" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-ti-super/" }],
        "fp16Tflops": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-ti-super/" }]
      }
    },
    {
      "id": "rtx-4080-super",
      "name": "RTX 4080 Super",
      "tier": "consumer",
      "vramGB": 16,
      "memoryBandwidthGBs": 736,
      "fp16Tflops": 104.4,
      "notes": "Ada Lovelace consumer GPU. FP16 TFLOPS includes sparsity.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080-super/" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080-super/" }],
        "fp16Tflops": [{ "label": "TechPowerUp", "url": "https://www.techpowerup.com/gpu-specs/geforce-rtx-4080-super.c4182" }]
      }
    },
    {
      "id": "rtx-4090",
      "name": "RTX 4090",
      "tier": "consumer",
      "vramGB": 24,
      "memoryBandwidthGBs": 1008,
      "fp16Tflops": 165.2,
      "notes": "Ada Lovelace consumer GPU. FP16 TFLOPS includes sparsity.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/" }],
        "fp16Tflops": [{ "label": "TechPowerUp", "url": "https://www.techpowerup.com/gpu-specs/geforce-rtx-4090.c3889" }]
      }
    },
    {
      "id": "rtx-a6000",
      "name": "RTX A6000",
      "tier": "workstation",
      "vramGB": 48,
      "memoryBandwidthGBs": 768,
      "fp16Tflops": 38.7,
      "notes": "Ampere workstation GPU. FP16 TFLOPS is for dense operations.",
      "sources": {
        "vramGB": [{ "label": "Binary Logic", "url": "https://www.binarylogic.com.bd/nvidia-rtx-a6000-48-gb-gddr6-graphics-card" }],
        "memoryBandwidthGBs": [{ "label": "Binary Logic", "url": "https://www.binarylogic.com.bd/nvidia-rtx-a6000-48-gb-gddr6-graphics-card" }],
        "fp16Tflops": [{ "label": "TechPowerUp", "url": "https://www.techpowerup.com/gpu-specs/rtx-a6000.c3682" }]
      }
    },
    {
      "id": "h100-sxm",
      "name": "H100 (SXM)",
      "tier": "datacenter",
      "vramGB": 80,
      "memoryBandwidthGBs": 3350,
      "fp16Tflops": 1979,
      "notes": "Hopper datacenter GPU. FP16 TFLOPS includes sparsity.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/data-center/h100/" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/data-center/h100/" }],
        "fp16Tflops": [{ "label": "NVIDIA", "url": "https://resources.nvidia.com/en-us-hopper-architecture/nvidia-h100-tensor-c" }]
      }
    },
    {
      "id": "h100-pcie",
      "name": "H100 (PCIe)",
      "tier": "datacenter",
      "vramGB": 80,
      "memoryBandwidthGBs": 2039,
      "fp16Tflops": 1513,
      "notes": "Hopper datacenter GPU. FP16 TFLOPS includes sparsity.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/data-center/h100/" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA", "url": "https://resources.nvidia.com/en-us-hopper-architecture/nvidia-h100-tensor-c" }],
        "fp16Tflops": [{ "label": "NVIDIA", "url": "https://resources.nvidia.com/en-us-hopper-architecture/nvidia-h100-tensor-c" }]
      }
    },
    {
      "id": "a100-80gb",
      "name": "A100 80GB (PCIe)",
      "tier": "datacenter",
      "vramGB": 80,
      "memoryBandwidthGBs": 1935,
      "fp16Tflops": 312,
      "notes": "Ampere datacenter GPU. FP16 TFLOPS includes sparsity.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/data-center/a100/" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/data-center/a100/" }],
        "fp16Tflops": [{ "label": "NVIDIA", "url": "https://www.nvidia.com/en-us/data-center/a100/" }]
      }
    },
    {
      "id": "rtx-5090",
      "name": "RTX 5090",
      "tier": "consumer",
      "vramGB": 32,
      "memoryBandwidthGBs": 1792,
      "fp16Tflops": 419.2,
      "notes": "Blackwell consumer GPU. Specs are based on reliable leaks and pre-release info.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA Compare Page", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/compare/#50-series" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA 5090 Page", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/rtx-5090/" }],
        "fp16Tflops": [{ "label": "NVIDIA Compare Page (Derived from AI TOPS)", "url": "https://www.nvidia.com/en-us/geforce/graphics-cards/compare/#50-series" }]
      }
    },
    {
      "id": "rtx-pro-6000-blackwell",
      "name": "RTX PRO 6000 (Blackwell)",
      "tier": "workstation",
      "vramGB": 96,
      "memoryBandwidthGBs": 1792,
      "fp16Tflops": 250,
      "notes": "Blackwell workstation GPU. FP16 TFLOPS is estimated based on FP32 performance.",
      "sources": {
        "vramGB": [{ "label": "NVIDIA Datasheet", "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/data-center/rtx-pro-6000-blackwell-workstation-edition/workstation-blackwell-rtx-pro-6000-workstation-edition-nvidia-us-3519208-web.pdf" }],
        "memoryBandwidthGBs": [{ "label": "NVIDIA Datasheet", "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/data-center/rtx-pro-6000-blackwell-workstation-edition/workstation-blackwell-rtx-pro-6000-workstation-edition-nvidia-us-3519208-web.pdf" }],
        "fp16Tflops": [{ "label": "NVIDIA Datasheet (Derived from FP32)", "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/data-center/rtx-pro-6000-blackwell-workstation-edition/workstation-blackwell-rtx-pro-6000-workstation-edition-nvidia-us-3519208-web.pdf" }]
      }
    }
  ],
  "models": [
    {
      "id": "llama-3-1-8b",
      "name": "Llama 3.1 8B",
      "family": "llama",
      "paramsB": 8,
      "defaultContext": 131072,
      "sources": {
        "paramsB": [{ "label": "Meta", "url": "https://ai.meta.com/blog/meta-llama-3-1/" }],
        "defaultContext": [{ "label": "Meta", "url": "https://ai.meta.com/blog/meta-llama-3-1/" }]
      }
    },
    {
      "id": "llama-3-1-70b",
      "name": "Llama 3.1 70B",
      "family": "llama",
      "paramsB": 70,
      "defaultContext": 131072,
      "sources": {
        "paramsB": [{ "label": "Meta", "url": "https://ai.meta.com/blog/meta-llama-3-1/" }],
        "defaultContext": [{ "label": "Meta", "url": "https://ai.meta.com/blog/meta-llama-3-1/" }]
      }
    },
    {
      "id": "mixtral-8x22b",
      "name": "Mixtral 8x22B",
      "family": "mistral",
      "paramsB": 141,
      "defaultContext": 65536,
      "notes": "Performance is based on ~40B active parameters per token.",
      "sources": {
        "paramsB": [{ "label": "Mistral AI", "url": "https://mistral.ai/news/mixtral-8x22b/" }],
        "defaultContext": [{ "label": "Mistral AI", "url": "https://mistral.ai/news/mixtral-8x22b/" }]
      }
    },
    {
      "id": "qwen-2-72b",
      "name": "Qwen 2 72B",
      "family": "qwen",
      "paramsB": 72,
      "defaultContext": 131072,
      "sources": {
        "paramsB": [{ "label": "Qwen Team", "url": "https://qwenlm.github.io/blog/qwen2/" }],
        "defaultContext": [{ "label": "Qwen Team", "url": "https://qwenlm.github.io/blog/qwen2/" }]
      }
    }
  ],
  "benchmarks": [
    {
      "id": "bench-4090-llama8b-fp16-4k",
      "gpuId": "rtx-4090",
      "modelId": "llama-3-1-8b",
      "context": 4096,
      "precision": "fp16",
      "mode": "single",
      "batchSize": 1,
      "concurrency": 1,
      "prefillTps": 950,
      "decodeTps": 125,
      "source": { "label": "Internal Estimate", "url": "", "date": "2024-07-01" }
    },
    {
      "id": "bench-h100-llama70b-fp16-8k",
      "gpuId": "h100-sxm",
      "modelId": "llama-3-1-70b",
      "context": 8192,
      "precision": "fp16",
      "mode": "throughput",
      "batchSize": 64,
      "concurrency": 64,
      "prefillTps": 20000,
      "decodeTps": 4000,
      "source": { "label": "Cloud Provider Estimate", "url": "", "date": "2024-07-01" }
    },
    {
      "id": "bench-a100-llama70b-fp16-4k",
      "gpuId": "a100-80gb",
      "modelId": "llama-3-1-70b",
      "context": 4096,
      "precision": "fp16",
      "mode": "single",
      "batchSize": 1,
      "concurrency": 1,
      "prefillTps": 400,
      "decodeTps": 38,
      "source": { "label": "Public Benchmark Analysis", "url": "", "date": "2024-06-15" }
    }
  ]
}